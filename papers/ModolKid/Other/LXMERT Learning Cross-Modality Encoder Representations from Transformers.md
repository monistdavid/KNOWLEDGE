Link
===============
<p>

LXMERT: Learning Cross-Modality Encoder Representations from Transformers
https://aclanthology.org/D19-1514.pdf

</p>

Summary
===============

    This paper purpose a model sturcture for multi-modality. Including encoder for language
    vision and relation between image and text. It largely improve the model's ability on
    answering image related question.

Questions From The Paper
===============


Additional Quesions and Personal Thoughts Based on little RESEARCH
===============



Creativity
==============
